{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccf7b97",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "Dans toute tâche d'apprentissage automatique, le nettoyage ou le prétraitement des données est aussi important que la construction du modèle. Les données textuelles sont l'une des formes les moins structurées de données disponibles et lorsqu'il s'agit de traiter le langage humain, c'est trop complexe. \n",
    "Dans ce Brief nous allons travailler sur le prétraitement des données textuelles en utilisant [NLTK](http://www.nltk.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d29f9",
   "metadata": {},
   "source": [
    "## Veille technologique: Natural Language processing (NLP)\n",
    "1- Les cas d'utlisation de NLP dans notre vie  \n",
    "2- Comment Facebook, Google et Amazon utilisent NLP  \n",
    "3- Préparation des données textuelles  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df871de1",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14aecb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importer les bibliothèques nécessaires\n",
    "import nltk\n",
    "\n",
    "def display(to_display):\n",
    "    print()\n",
    "    print(to_display)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# télécharger les données NLTK \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79a5cf",
   "metadata": {},
   "source": [
    "## Nettoyage des données\n",
    "\n",
    "Dans cette partie nous allons utiliser [NLTK](http://www.nltk.org) pour nettoyer un texte de [wikipidéa](https://en.wikipedia.org/wiki/Natural_language_processing) sur la définition du NLP  \n",
    "\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6bf760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "natural language processing (nlp) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. the goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lowercase: mettre tout le texte en minuscule\n",
    "text= 'Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'\n",
    "\n",
    "text = text.lower() \n",
    "\n",
    "display(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463e7d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "natural language processing nlp is a subfield of linguistics computer science and artificial intelligence concerned with the interactions between computers and human language in particular how to program computers to process and analyze large amounts of natural language data the goal is a computer capable of understanding the contents of documents including the contextual nuances of the language within them the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# supprimer les ponctuations\n",
    "import string\n",
    "\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "display(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3cdd6",
   "metadata": {},
   "source": [
    "### Word Tokenization\n",
    "La tokénisation([Tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual)) consiste à diviser les chaînes de caractères en mots individuels sans blancs ni tabulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4cf7be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['natural', 'language', 'processing', 'nlp', 'is', 'a', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', 'the', 'goal', 'is', 'a', 'computer', 'capable', 'of', 'understanding', 'the', 'contents', 'of', 'documents', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', 'the', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "display(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec18ba3",
   "metadata": {},
   "source": [
    "\n",
    "### Stopwords\n",
    "Les mots d'arrêts sont des mots qui n'ajoutent pas de sens significatif au texte. Utiliser NLTK pour lister les stop words et les supprimer du texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad98be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "\n",
      "    > Length with stopwords: 82\n",
      "\n",
      "\n",
      "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', 'goal', 'computer', 'capable', 'understanding', 'contents', 'documents', 'including', 'contextual', 'nuances', 'language', 'within', 'technology', 'accurately', 'extract', 'information', 'insights', 'contained', 'documents', 'well', 'categorize', 'organize', 'documents']\n",
      "\n",
      "\n",
      "    > Length without stopwords: 47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# récupérer les stopwords\n",
    "english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "display(english_stopwords)\n",
    "\n",
    "# supprimer les stopwords\n",
    "display(\"    > Length with stopwords: \" + str(len(tokens)))\n",
    "\n",
    "tokens = [word for word in tokens if word not in english_stopwords]\n",
    "\n",
    "display(tokens)\n",
    "display(\"    > Length without stopwords: \" + str(len(tokens)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25588009",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "L'étymologie est le processus qui consiste à réduire les mots à leur racine, leur base ou leur forme ([Stemming](https://en.wikipedia.org/wiki/Stemming))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5418434",
   "metadata": {},
   "source": [
    "## Développement des fonctions\n",
    "\n",
    "Développer chaque étape du prétraitement du texte dans une fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca52186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['natur', 'languag', 'process', 'nlp', 'subfield', 'linguist', 'comput', 'scienc', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', 'languag', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', 'goal', 'comput', 'capabl', 'understand', 'content', 'document', 'includ', 'contextu', 'nuanc', 'languag', 'within', 'technolog', 'accur', 'extract', 'inform', 'insight', 'contain', 'document', 'well', 'categor', 'organ', 'document']\n",
      "\n",
      "\n",
      "    > Length tokens: 47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lowercase: mettre tout le texte en minuscule\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# supprimer les ponctuations\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "# tokenization\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "# stopwords\n",
    "def remove_stopwords(words, lang = 'english'):\n",
    "    _stopwords = nltk.corpus.stopwords.words(lang)\n",
    "    return [word for word in words if word not in _stopwords]\n",
    "    \n",
    "# stemming\n",
    "def stemmize(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "tokens = stemmize(tokens) \n",
    "\n",
    "display(tokens)\n",
    "display(\"    > Length tokens: \" + str(len(tokens)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3610110",
   "metadata": {},
   "source": [
    "# What about Twitter messages !! :)\n",
    "\n",
    "Dans cette partie nous allons appliquer les étapes de prétraitement de texte sur une base de données des messages Twitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c886a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk                                \n",
    "from nltk.corpus import twitter_samples    \n",
    "import matplotlib.pyplot as plt            \n",
    "import random       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d270188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('twitter_samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "979b2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "061ed30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m@aaronbethunee I'm sofa surfing :) cunt\n",
      "\n",
      "\n",
      "\u001b[91m@thebodycoach Joe I'm sick can you come round and make me soup ? :(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print positive in greeen\n",
    "display('\\033[92m' + all_positive_tweets[random.randint(0, 5000)])\n",
    "\n",
    "# print negative in red\n",
    "display('\\033[91m' + all_negative_tweets[random.randint(0, 5000)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
